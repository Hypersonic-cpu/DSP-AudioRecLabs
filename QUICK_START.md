# å¿«é€Ÿå¼€å§‹æŒ‡å—

## ğŸ“¦ å®‰è£…ä¾èµ–

é¦–å…ˆç¡®ä¿å®‰è£…æ‰€æœ‰å¿…è¦çš„PythonåŒ…ï¼š

```bash
cd /Users/ding/Desktop/DesktopAir/DSP/DSP-TimeDomainAudioRec
pip install -r requirements.txt
```

**æ³¨æ„**ï¼šå¦‚æœPyTorchå®‰è£…å¤±è´¥ï¼Œè¯·ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤ï¼š

```bash
# macOS (Apple Silicon)
pip install torch torchvision torchaudio

# macOS (Intel)
pip install torch torchvision torchaudio

# æˆ–è€…ä½¿ç”¨conda
conda install pytorch torchvision torchaudio -c pytorch
```

## ğŸ¯ ä¸»è¦åŠŸèƒ½

### 1. æ•°æ®é›†åˆ‡æ¢

é¡¹ç›®æ”¯æŒä¸¤ä¸ªæ•°æ®é›†ï¼š
- **ä¸­æ–‡åå­—æ•°æ®é›†**ï¼š`~/Downloads/speech_data_name`
- **æ•°å­—æ•°æ®é›†**ï¼š`~/Downloads/speech_data_number`

**åˆ‡æ¢æ–¹æ³•**ï¼š

åœ¨ [config.py](config.py#L13) ä¸­ä¿®æ”¹ï¼š

```python
DATASET_TYPE = 'name'   # ä¸­æ–‡åå­—
# æˆ–
DATASET_TYPE = 'number' # æ•°å­—
```

### 2. å¿«é€Ÿè®­ç»ƒ

ä½¿ç”¨æ–°çš„æ ¸å¿ƒè®­ç»ƒæ¨¡å— [train_model.py](train_model.py) å¿«é€Ÿè®­ç»ƒæ¨¡å‹ï¼š

```bash
# ä½¿ç”¨é»˜è®¤å‚æ•°è®­ç»ƒMLP
python train_model.py

# è¾“å‡ºç¤ºä¾‹ï¼š
# å‡†ç¡®ç‡: 0.9500
```

### 3. è¿è¡Œæ¶ˆèå®éªŒ

#### å­¦ä¹ ç‡å¯¹æ¯”

å¯¹æ¯”ä¸åŒå­¦ä¹ ç‡å¯¹MLPæ€§èƒ½çš„å½±å“ï¼š

```bash
# åœ¨ä¸­æ–‡åå­—æ•°æ®é›†ä¸Šæµ‹è¯•
python ablation_study.py --experiment lr --dataset name

# åœ¨æ•°å­—æ•°æ®é›†ä¸Šæµ‹è¯•
python ablation_study.py --experiment lr --dataset number
```

**ç»“æœä½ç½®**ï¼š`results/ablation_learning_rate/`

#### å¸§é•¿å¯¹æ¯”

å¯¹æ¯”ä¸åŒå¸§é•¿ï¼ˆé‡‡æ ·çª—å£å¤§å°ï¼‰å¯¹æ€§èƒ½çš„å½±å“ï¼š

```bash
python ablation_study.py --experiment frame_length --dataset name
```

**ç»“æœä½ç½®**ï¼š`results/ablation_frame_length/`

#### å¸§ç§»å¯¹æ¯”

å¯¹æ¯”ä¸åŒå¸§ç§»ï¼ˆå¸§ä¹‹é—´çš„é‡å ç¨‹åº¦ï¼‰å¯¹æ€§èƒ½çš„å½±å“ï¼š

```bash
python ablation_study.py --experiment frame_shift --dataset name
```

**ç»“æœä½ç½®**ï¼š`results/ablation_frame_shift/`

#### è¿è¡Œæ‰€æœ‰å®éªŒ

```bash
# åœ¨ä¸­æ–‡åå­—æ•°æ®é›†ä¸Šè¿è¡Œæ‰€æœ‰æ¶ˆèå®éªŒ
python ablation_study.py --experiment all --dataset name

# åœ¨æ•°å­—æ•°æ®é›†ä¸Šè¿è¡Œæ‰€æœ‰æ¶ˆèå®éªŒ
python ablation_study.py --experiment all --dataset number
```

### 4. åŸæœ‰åŠŸèƒ½ï¼ˆå®Œæ•´å®éªŒæµç¨‹ï¼‰

è¿è¡ŒåŸæœ‰çš„å®Œæ•´å®éªŒæµç¨‹ï¼š

```bash
# è¿è¡Œæ‰€æœ‰å®éªŒ
python run.py --experiment all

# åªè¿è¡Œåˆ†ç±»å™¨å¯¹æ¯”
python run.py --experiment classifier

# åªè¿è¡Œçª—å‡½æ•°å¯¹æ¯”
python run.py --experiment window

# å¯è§†åŒ–æ ·æœ¬
python run.py --experiment visualize
```

## ğŸ“Š ç»“æœæŸ¥çœ‹

æ‰€æœ‰å®éªŒç»“æœä¿å­˜åœ¨ `results/` ç›®å½•ä¸‹ï¼š

```
results/
â”œâ”€â”€ ablation_learning_rate/      # å­¦ä¹ ç‡æ¶ˆèå®éªŒ
â”‚   â”œâ”€â”€ learning_rate_comparison.png
â”‚   â”œâ”€â”€ results.json
â”‚   â””â”€â”€ results_summary.txt
â”œâ”€â”€ ablation_frame_length/       # å¸§é•¿æ¶ˆèå®éªŒ
â”‚   â”œâ”€â”€ frame_length_comparison.png
â”‚   â”œâ”€â”€ results.json
â”‚   â””â”€â”€ results_summary.txt
â”œâ”€â”€ ablation_frame_shift/        # å¸§ç§»æ¶ˆèå®éªŒ
â”‚   â”œâ”€â”€ frame_shift_comparison.png
â”‚   â”œâ”€â”€ results.json
â”‚   â””â”€â”€ results_summary.txt
â”œâ”€â”€ exp1_classifier_comparison/  # åˆ†ç±»å™¨å¯¹æ¯”
â”œâ”€â”€ exp2_window_comparison/      # çª—å‡½æ•°å¯¹æ¯”
â””â”€â”€ exp3_feature_analysis/       # ç‰¹å¾åˆ†æ
```

## ğŸ¨ ä¸­æ–‡æ˜¾ç¤º

ä»£ç å·²ç»é…ç½®å¥½ä¸­æ–‡å­—ä½“æ”¯æŒï¼Œå›¾è¡¨ä¸­çš„ä¸­æ–‡åå­—ä¼šæ­£ç¡®æ˜¾ç¤ºã€‚

å¦‚æœé‡åˆ°ä¸­æ–‡æ˜¾ç¤ºé—®é¢˜ï¼Œè¯·æ£€æŸ¥ï¼š

1. matplotlibçš„å­—ä½“é…ç½®
2. ç³»ç»Ÿä¸­æ˜¯å¦å®‰è£…äº†ä¸­æ–‡å­—ä½“ï¼ˆmacOSè‡ªå¸¦ï¼‰

å¯è§†åŒ–æ¨¡å— [src/visualization.py](src/visualization.py) ä¼šè‡ªåŠ¨æ£€æµ‹å¹¶ä½¿ç”¨ä»¥ä¸‹å­—ä½“ï¼š
- Arial Unicode MSï¼ˆmacOSï¼‰
- PingFang SCï¼ˆè‹¹æ–¹ï¼‰
- Heiti SCï¼ˆé»‘ä½“-ç®€ï¼‰
- ç­‰ç­‰

## âš™ï¸ å‚æ•°é…ç½®

### ä¸»è¦å‚æ•°

åœ¨ [config.py](config.py) ä¸­å¯ä»¥ä¿®æ”¹ï¼š

```python
# æ•°æ®é›†é€‰æ‹©
DATASET_TYPE = 'name'  # 'name' æˆ– 'number'

# éŸ³é¢‘å¤„ç†å‚æ•°
FRAME_LENGTH_MS = 20   # å¸§é•¿ï¼ˆæ¯«ç§’ï¼‰
FRAME_SHIFT_MS = 10    # å¸§ç§»ï¼ˆæ¯«ç§’ï¼‰

# MLPè®­ç»ƒå‚æ•°
MLP_LEARNING_RATE = 0.005
MLP_EPOCHS = 1000
MLP_BATCH_SIZE = 108

# æ¶ˆèå®éªŒå‚æ•°
LEARNING_RATES = [0.0001, 0.0005, 0.001, 0.005, 0.01, 0.05]
FRAME_LENGTH_MS_RANGE = [10, 15, 20, 25, 30, 40]
FRAME_SHIFT_MS_RANGE = [5, 10, 15, 20, 25]
```

## ğŸ’¡ ä»£ç ç»“æ„

```
DSP-TimeDomainAudioRec/
â”œâ”€â”€ config.py                    # é…ç½®æ–‡ä»¶ï¼ˆä¿®æ”¹å‚æ•°ï¼‰
â”œâ”€â”€ train_model.py               # æ ¸å¿ƒè®­ç»ƒæ¨¡å—ï¼ˆæ–°å¢ï¼‰
â”œâ”€â”€ ablation_study.py            # æ¶ˆèå®éªŒè„šæœ¬ï¼ˆæ–°å¢ï¼‰
â”œâ”€â”€ run.py                       # åŸæœ‰è¿è¡Œè„šæœ¬
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ models.py               # åˆ†ç±»å™¨æ¨¡å‹
â”‚   â”œâ”€â”€ audio_processing.py     # éŸ³é¢‘å¤„ç†
â”‚   â”œâ”€â”€ feature_extraction.py   # ç‰¹å¾æå–
â”‚   â””â”€â”€ visualization.py        # å¯è§†åŒ–ï¼ˆæ”¯æŒä¸­æ–‡ï¼‰
â””â”€â”€ experiments/
    â””â”€â”€ run_experiments.py      # å®Œæ•´å®éªŒæµç¨‹
```

## ğŸ” ç¤ºä¾‹å·¥ä½œæµ

### åœºæ™¯1ï¼šå¯¹æ¯”ä¸¤ä¸ªæ•°æ®é›†çš„æ€§èƒ½

```bash
# 1. åœ¨ä¸­æ–‡åå­—æ•°æ®é›†ä¸Šè®­ç»ƒ
python ablation_study.py --experiment all --dataset name

# 2. åœ¨æ•°å­—æ•°æ®é›†ä¸Šè®­ç»ƒ
python ablation_study.py --experiment all --dataset number

# 3. å¯¹æ¯”ç»“æœ
# æŸ¥çœ‹ results/ablation_*/results_summary.txt
```

### åœºæ™¯2ï¼šæ‰¾åˆ°æœ€ä½³å­¦ä¹ ç‡

```bash
# è¿è¡Œå­¦ä¹ ç‡æ¶ˆèå®éªŒ
python ablation_study.py --experiment lr --dataset name

# æŸ¥çœ‹ç»“æœ
cat results/ablation_learning_rate/results_summary.txt

# è¾“å‡ºä¼šæ˜¾ç¤ºæœ€ä½³å­¦ä¹ ç‡ï¼Œä¾‹å¦‚ï¼š
# æœ€ä½³å‚æ•°: 0.005
# æœ€ä½³å‡†ç¡®ç‡: 0.9500
```

### åœºæ™¯3ï¼šå¿«é€Ÿæµ‹è¯•ä¸åŒå‚æ•°

ä½¿ç”¨Pythonäº¤äº’å¼ç¯å¢ƒï¼š

```python
from train_model import quick_experiment

# æµ‹è¯•ä¸åŒå­¦ä¹ ç‡
for lr in [0.001, 0.005, 0.01]:
    result = quick_experiment(learning_rate=lr, verbose=False)
    print(f"LR={lr}: Accuracy={result['accuracy']:.4f}")

# æµ‹è¯•ä¸åŒå¸§é•¿
for frame_len in [15, 20, 25]:
    result = quick_experiment(frame_length_ms=frame_len, verbose=False)
    print(f"Frame={frame_len}ms: Accuracy={result['accuracy']:.4f}")
```

## â“ å¸¸è§é—®é¢˜

### Q1: å¦‚ä½•åªè¿è¡Œä¸€ä¸ªç®€å•çš„æµ‹è¯•ï¼Ÿ

```bash
python train_model.py
```

è¿™ä¼šä½¿ç”¨é»˜è®¤å‚æ•°å¿«é€Ÿè®­ç»ƒä¸€ä¸ªMLPæ¨¡å‹ã€‚

### Q2: æ¶ˆèå®éªŒéœ€è¦å¤šé•¿æ—¶é—´ï¼Ÿ

- å­¦ä¹ ç‡å®éªŒï¼šçº¦10-30åˆ†é’Ÿï¼ˆå–å†³äºæ ·æœ¬æ•°ï¼‰
- å¸§é•¿å®éªŒï¼šçº¦30-60åˆ†é’Ÿï¼ˆéœ€è¦é‡æ–°æå–ç‰¹å¾ï¼‰
- å¸§ç§»å®éªŒï¼šçº¦30-60åˆ†é’Ÿï¼ˆéœ€è¦é‡æ–°æå–ç‰¹å¾ï¼‰

### Q3: å¦‚ä½•è‡ªå®šä¹‰æ¶ˆèå®éªŒçš„å‚æ•°èŒƒå›´ï¼Ÿ

åœ¨ [config.py](config.py#L77-L84) ä¸­ä¿®æ”¹ï¼š

```python
LEARNING_RATES = [0.001, 0.005, 0.01]  # è‡ªå®šä¹‰å­¦ä¹ ç‡èŒƒå›´
FRAME_LENGTH_MS_RANGE = [15, 20, 25]   # è‡ªå®šä¹‰å¸§é•¿èŒƒå›´
```

### Q4: å¦‚ä½•ä½¿ç”¨ä¸åŒçš„åˆ†ç±»å™¨è¿›è¡Œæ¶ˆèå®éªŒï¼Ÿ

```bash
# ä½¿ç”¨SVM
python ablation_study.py --experiment frame_length --classifier svm

# ä½¿ç”¨KNN
python ablation_study.py --experiment frame_shift --classifier knn
```

**æ³¨æ„**ï¼šå­¦ä¹ ç‡å®éªŒä»…é€‚ç”¨äºMLPã€‚

## ğŸ“š æ›´å¤šæ–‡æ¡£

- [ABLATION_EXPERIMENTS.md](ABLATION_EXPERIMENTS.md) - è¯¦ç»†çš„æ¶ˆèå®éªŒè¯´æ˜
- [README.md](README.md) - é¡¹ç›®æ€»ä½“ä»‹ç»

## ğŸš€ ç«‹å³å¼€å§‹

```bash
# 1. å®‰è£…ä¾èµ–
pip install -r requirements.txt

# 2. å¿«é€Ÿæµ‹è¯•
python train_model.py

# 3. è¿è¡Œæ¶ˆèå®éªŒ
python ablation_study.py --experiment all --dataset name

# 4. æŸ¥çœ‹ç»“æœ
ls -la results/ablation_*
```

ç¥å®éªŒé¡ºåˆ©ï¼ğŸ‰
